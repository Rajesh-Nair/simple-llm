# Sample train_config.yaml:

paths:
  model_save_path: "../simple-llm-gpt2-v3.0" # Path to save the model
  model_load_path: "../simple-llm-gpt2-v3.0" # Path to load the model
  tokenizer_save_path: "../simple-llm-gpt2-v3.0" # Path to save the tokenizer
  tokenizer_file: "tokenizer.json" # Tokenizer file name

pre_processing:
  replace_column_delimiter : "+" # None
  reverse_series : True  # False
  column_delimiter : " " # "|"
  sub_seq_add : False # False

tokenizer:
  vocab_size: 11  # Or desired vocabulary size
  special_tokens:
    - "<|UNK|>"
    - "<|pad|>"
  ##min_frequency: 2
  #continuing_subword_prefix: "##"

model:
  n_positions: 64      # Maximum sequence length
  n_embd: 256          # Embedding dimension
  n_layer: 8           # Number of transformer layers
  n_head: 4            # Number of attention heads
  activation_function: "gelu" # Activation function
  resid_pdrop: 0.1     # Dropout probability for residual layers
  embd_pdrop: 0.1      # Dropout probability for embeddings
  attn_pdrop: 0.1      # Dropout probability for attention
  layer_norm_epsilon: 0.00001 # Layer norm epsilon
  bos_token_id : None # Beginning of sequence token id
  eos_token_id : None # End of sequence token id

training:
  load_checkpoint: https://huggingface.co/mirajnair/simple-llm-gpt2-v3.0 # Load checkpoint path "../simple-llm-gpt2-v3.0" or null or huggingface model repo path (https://huggingface.co/mirajnair/simple-llm-gpt2-v3.0)
  per_device_batch_size: 1024 # Batch size
  learning_rate: 0.00010 # Learning rate
  num_epochs: 300 # Number of epochs
  device: "cuda" # Use "cuda" for GPU, "cpu" for CPU
  num_workers: 2 # Number of workers - single node
  warmup_steps: 100 # Warmup steps
  gradient_accumulation_steps: 2  # Gradient accumulation steps
  max_grad_norm: 1.0 # Maximum gradient norm
  weight_decay: 0.01 # Weight decay
  eval_interval: 1 # Evaluation interval and save interval
  per_device_eval_batch_size: 1024 # Evaluation batch size  
  early_stopping: 5 # Early stopping patience
  upload_to_huggingface: True # Upload to Hugging Face Hub
  generate_text_steps : null # Generate text steps
  generate_text_length : 512 # Generate text length
  generate_text_input : "1 1 2 3 5 8 " # Generate text input

wandb:
  enabled: True # Enable wandb
  project_name: "simple-llm-gpt2-v3.0" # Wandb project name
  entity: "mirajnair" # Wandb entity


